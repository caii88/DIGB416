# -*- coding: utf-8 -*-
"""W13_YANG FENGYU_2022390606

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ifWd3va4XFNB6zKHrQBFty-S0yGXx8GC

## Cohort Analysis
"""

import numpy as np
import pandas as pd
import datetime as dt

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

"""### Understand Data

#### Load data
"""

data = pd.read_csv('/content/online_retail.csv', index_col=False)

data.head()

data.info()

for x in data.columns:
    print(x)
    print(data[x].values)

"""### Preprocessing"""

df = data.copy()

"""#### Drop index col"""

df = df.drop(columns='index')

"""#### Check Null values"""

df.isnull().sum()

"""#### Drop missing values"""

df= df.dropna(subset=['CustomerID'])

df.isnull().sum()

"""#### Check & Drop Duplicates"""

print(df.duplicated().sum())

df = df.drop_duplicates()

print(df.duplicated().sum())

"""#### Change Datatype
- customer ID: String
"""

df['CustomerID'] = df['CustomerID'].astype(int).astype(str)
df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])

df.dtypes

df.describe()

df.shape

"""#### Quantity & Unit Price Filter
- Filter Quantity > 0 & Unit Price > 0
"""

df[df['Quantity']<0]

df[df['StockCode'].str.len() == 1][['StockCode','Description']].value_counts()

df[(df['Quantity']<0) & (df['InvoiceNo'] == 'C536379')]

df[(df['Quantity']<0) & (df['Description'] == 'Discount')][['StockCode','Description']].value_counts()

df[df['UnitPrice']==0]

df = df[(df['Quantity']>0) & (df['UnitPrice']>0)]

df.shape

"""## EDA"""

df.describe()

df['CustomerID']

"""### Understand Values"""

print(f"Number of unique invoices: {df['InvoiceNo'].nunique()}")
print(f"Number of unique products: {df['StockCode'].nunique()}")
print(f"Number of unique descriptions: {df['Description'].nunique()}")

print(f"Most common products:\n{df['Description'].value_counts().head(10)}")

"""### Distribution of Qty"""

# Define custom bin ranges
bin_ranges = list(range(0, 1001, 50))  # Bins from 0 to 1000 in increments of 50

# Plot histogram with custom bins
plt.figure(figsize=(10, 6))
sns.histplot(df['Quantity'], bins=bin_ranges, kde=False)
plt.title('Distribution of Quantity (Custom Bins)')
plt.xlabel('Quantity')
plt.ylabel('Frequency')
plt.show()

# Apply log transformation to Quantity
df['Log_Quantity'] = df['Quantity'].apply(lambda x: np.log1p(x) if x > 0 else 0)

# Plot histogram of log-transformed data
plt.figure(figsize=(10, 6))
sns.histplot(df['Log_Quantity'], bins=50, kde=True)
plt.title('Distribution of Log-Transformed Quantity')
plt.xlabel('Log(Quantity)')
plt.ylabel('Frequency')
plt.show()

"""### Distribution of Transaction"""

df['YearMonth'] = df['InvoiceDate'].dt.to_period('M')

plt.figure(figsize=(15, 6))
df['YearMonth'].value_counts().sort_index().plot(kind='bar')
plt.title('Transactions Over Time')
plt.xlabel('Year-Month')
plt.ylabel('Number of Transactions')
plt.show()

"""### Customer location"""

print("\nCountry Analysis:")
print(f"Number of unique countries: {df['Country'].nunique()}")
print(f"Top 10 countries by transactions:\n{df['Country'].value_counts().head(10)}")

# Transactions by country
plt.figure(figsize=(15, 8))
df['Country'].value_counts().plot(kind='bar')
plt.title('Transactions by Country')
plt.ylabel('Number of Transactions')
plt.show()

"""## Cohort Analysis
- Cohort group: 고객의 첫번째 구매 날짜
"""

df1 = df.copy()

### Get Month
df1['InvoiceMonth'] = df1['InvoiceDate'].dt.date

df1.tail()

"""#### Cohort Month: 고객의 첫 구매 날짜"""

### Get Cohort Month
df1['FirstOrderDate'] = df1.groupby('CustomerID')['InvoiceMonth'].transform('min')

df1.head()

df1.tail()

## Check value
df1[df1['CustomerID'] == '12680'][['InvoiceMonth', 'FirstOrderDate']].value_counts()

df1[df1['CustomerID'] == '17850'][['InvoiceMonth', 'FirstOrderDate']].value_counts()

df1.dtypes

"""### Cohort Index
- 각 코호트의 월별 활성과 고객수를 계산
"""

### Change FirstOrderDate to dataframe dtype
df1['InvoiceMonth'] = pd.to_datetime(df1['InvoiceMonth'])
df1['FirstOrderDate'] = pd.to_datetime(df1['FirstOrderDate'])
# 월의 첫째날 가져오기
df1['InvoiceMonth'] = df1['InvoiceDate'].dt.to_period('M').dt.to_timestamp()
df1['FirstOrderDate'] = df1['FirstOrderDate'].dt.to_period('M').dt.to_timestamp()

df1.dtypes

df1['FirstOrderDate'].value_counts()

df1[['FirstOrderDate']].value_counts()

df1[df1['FirstOrderDate'] == '2011-01-01'][['FirstOrderDate','InvoiceMonth']].value_counts()

df1['CohortIndex'] = (
    (df1['InvoiceMonth'].dt.year - df1['FirstOrderDate'].dt.year) * 12 +
    (df1['InvoiceMonth'].dt.month - df1['FirstOrderDate'].dt.month) #+ 1
)

df1.head()

df1[df1['CustomerID'] == '12680'][['InvoiceMonth', 'FirstOrderDate','CohortIndex']]

df1.describe()

cohort_counts = (
    df1.groupby(['FirstOrderDate', 'CohortIndex'])['CustomerID']
    .nunique() #각 그룹의 고유 고객 수(CustomerID)를 직접 계산)
    .unstack() #Reshapes the grouped data into a pivot table
)
cohort_counts

plt.figure(figsize=(15, 8))
plt.title('Customer Cohort Analysis : Count')
sns.heatmap(data=cohort_counts,annot = True,vmin = 0.0,fmt=".0f",cmap="coolwarm")
plt.show()

"""### Retention Rate table
- Customer retention Rate(고객 유지율): 전체 고객 중 얼마나 많은 고객이 여전히 활성 상태인지 이해하는 데 매우 유용한 지표 -> 유지는 "총 고객 수"와 비교하여 "활성 고객의 비율"을 제공
"""

cohort_size = cohort_counts.iloc[:,0]
retention = cohort_counts.divide(cohort_size,axis=0) #axis=0 to ensure the divide along the row axis
retention.round(3) * 100 #백분율 표시

cohort_size

324/885

286.0/885

"""#### Retention Heatmap"""

plt.figure(figsize=(15, 8))
plt.title('Retention rates')
sns.heatmap(data=retention,annot = True,fmt = '.1%',vmin = 0.0,vmax = 0.5,cmap="coolwarm")
plt.show()

"""### Average Qty for each Cohort"""

average_quantity = (
    df1.groupby(['FirstOrderDate', 'CohortIndex'])['Quantity']
    .mean()
    .unstack()
    .round(1)
)

average_quantity

"""#### Average Qty Heatmap"""

plt.figure(figsize=(15, 8))
plt.title('Average quantity for each cohort')
sns.heatmap(data=average_quantity,annot = True,vmin = 0.0,vmax =20,cmap="coolwarm")
plt.show()

"""### Net Revenue by Cohort"""

df1['Sales'] = df1['Quantity'] * df1['UnitPrice']

cohort_revenue = (
    df1.groupby(['FirstOrderDate', 'CohortIndex'])['Sales'].sum()
    .unstack() #Reshapes the grouped data into a pivot table
)
cohort_revenue

plt.figure(figsize=(15, 8))
plt.title('Net Revenue for each cohort')
sns.heatmap(data=cohort_revenue,annot = True,vmin = 0.0,fmt=".0f",cmap="coolwarm")
plt.show()

"""### Cohort Cumulative Lifetime Revenue"""

cohort_cumulative_revenue = (
    df1.groupby(['FirstOrderDate', 'CohortIndex'])['Sales'].sum()
    .unstack()  # Reshapes the grouped data into a pivot table
    .cumsum(axis=1)  # Calculates the cumulative sum across columns (CohortIndex)
)
cohort_cumulative_revenue

plt.figure(figsize=(15, 8))
plt.title('Cohort Cumulative Lifetime Revenue')
sns.heatmap(data=cohort_cumulative_revenue,annot = True,vmin = 0.0,fmt=".0f",cmap="coolwarm")
plt.show()